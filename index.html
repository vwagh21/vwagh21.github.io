<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Vaidehi Wagh</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" />
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <!-- NAVBAR -->
  <nav>
    <a href="index.html">Home</a>
    <a href="projects.html">Projects</a>
    <a href="publications.html">Publications</a>
    <a href="cv.html">CV</a>
    <a href="fun.html">Fun Stuff</a>
  </nav>

  <div class="container">

    <!-- LEFT COLUMN -->
    <div class="left">
      <div class="carousel">
        <img src="images/profpic1.jpg" class="active" alt="Profile photo 1">
        <img src="images/profpic2.jpg" alt="Profile photo 2">
        <img src="images/profpic3.jpg" alt="Profile photo 3">
      </div>

      <ul class="profile-info">
        <li class="name">Vaidehi Wagh</li>
        <li class="subtitle">MS in Robotics, Carnegie Mellon</li>
        <li class="subtitle">ML · Robotics · HRI</li>
        <li><a href="mailto:vwagh@cs.cmu.edu"><i class="fas fa-envelope"></i> Email</a></li>
        <li><a href="https://github.com/vwagh21"><i class="fab fa-github"></i> GitHub</a></li>
        <li><a href="https://scholar.google.com/citations?user=A9XFkDcAAAAJ"><i class="fas fa-graduation-cap"></i> Google Scholar</a></li>
        <li><a href="https://www.linkedin.com/in/vaidehi-wagh-b08286197"><i class="fab fa-linkedin"></i> LinkedIn</a></li>
        <li><a href="Wagh_Vaidehi_web_version.pdf"><i class="fas fa-file"></i> CV</a></li>
      </ul>
    </div>

    <!-- RIGHT COLUMN -->
    <div class="right">
      <h2>About</h2>
      <p>
        I’m a second-year Master’s student in Robotics at Carnegie Mellon University, 
        working with <a href="https://metamobility.cmu.edu/people/inseung-kang">Dr. Inseung Kang</a> 
        in the <a href="https://metamobility.cmu.edu/home">MetaMobility Lab</a>. My research focuses on using 
        large and small language models on edge to personalize wearable robot control and build 
        human-robot interaction interfaces, with an emphasis on adapting exoskeletons to diverse 
        user needs through transfer learning and temporal deep learning methods.
      </p> 
      <p> 
        Before CMU, I worked with <a href="https://news.ok.ubc.ca/2024/01/22/ubco-research-gives-stroke-survivors-control/">Dr. Sarah Kraeutner</a> 
        at the University of British Columbia, validating computer-vision-based kinematic assessment tools for post-stroke rehabilitation, and spent time 
        as a Financial Analyst at Deloitte. I completed my Bachelor’s in Mechanical Engineering at COEP Tech University in Pune, India.
      </p>
      <p>
        I have experience spanning computer vision, mechatronics, and edge deployment, 
        and I’m broadly interested in medical and healthcare robotics where AI and human-centered 
        design create assistive technologies that meaningfully improve lives.
      </p>
      <p>
        <strong>I am seeking full-time opportunities in ML, AI, robotics, or research engineering starting May 2026.</strong>
      </p>

      <!-- PROJECTS -->
      <h2>Projects</h2>
      <div class="projects">
        <div class="project-card">
          <img src="images/llm_hri.png" alt="LLM Human-Robot Interface">
          <div class="project-info">
            <strong>LLM-based Human-Robot Voice Interface – Talking to Robots</strong>
            <p><em>SLMs, Phi4, SFT, Jetson Orin Nano</em></p>
            <p>Developed a human-robot interface using speech and vision inputs to finetune a mini VLM for long-horizon planning and execution of user-personalized lower limb exoskeleton control.</p>
          </div>
        </div>

        <div class="project-card">
          <img src="images/iv_bot.png" alt="Automated IV Insertion Bot">
          <div class="project-info">
            <strong>Automated IV Insertion Bot – Medical Robotics</strong>
            <p><em>Autodesk, CAD, 3D Printing, Electronics, Control</em></p>
            <p>Designed linear-actuation mechanisms for needle insertion, integrating Arduino control, computer vision-based vein localization, and control algorithms for the robot arm.</p>
          </div>
        </div>

        <div class="project-card">
          <img src="images/gail.png" alt="Generative Adversarial Imitation Learning">
          <div class="project-info">
            <strong>Generative Adversarial Imitation Learning – Intro to Robot Learning</strong>
            <p><em>Inverse reinforcement learning, GAIL</em></p>
            <p>Applied inverse reinforcement learning with GAN-based reward models to simulate human locomotion, exploring state-level and trajectory-level GAIL approaches.</p>
          </div>
        </div>
      </div>

      <!-- PUBLICATIONS -->
      <h2>Publications & Presentations</h2>
      <div class="publications">
        <p>[1] <em><strong>Wagh, V.</strong>, Park, D., Young, A. J., & Kang, I.</em> Transfer learning for biological joint moment estimation in stroke populations. <a href="https://asbweb.org/wp-content/uploads/ASB-2025-Abstract-Book-Posters-v2.pdf">Abstract</a></p>

        <p>[2] <em><strong>Wagh, V.</strong>, Scott, M. W., Andrushko, J. W., Jones, C. B., Boyd, L.A, & Kraeutner, S. N.</em> Using MediaPipe to track upper-limb movement after stroke: a proof-of-principle study. <a href="https://link.springer.com/article/10.1186/s12984-025-01808-4">Journal Paper</a></p>

        <p>[3] <em><strong>Wagh, V.</strong>, Scott, M. W., & Kraeutner, S. N.</em> Quantifying Similarities Between MediaPipe and a Known Standard to Address Issues in Tracking 2D Upper Limb Trajectories: Proof of Concept Study. <a href="https://formative.jmir.org/2024/1/e56682/">Journal Paper</a></p>
      </div>

    </div>
  </div>

  <!-- CAROUSEL SCRIPT -->
  <script>
    const images = document.querySelectorAll('.carousel img');
    let current = 0;
    setInterval(() => {
      images[current].classList.remove('active');
      current = (current + 1) % images.length;
      images[current].classList.add('active');
    }, 3000);
  </script>
</body>
</html>
